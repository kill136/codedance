2025-01-18 16:49:05,025 [INFO] 设置 pad_token 为 eos_token: </s>
2025-01-18 16:49:06,970 [INFO] 成功加载预训练权重: ./out/pretrain_512.pth
2025-01-18 16:49:06,971 [INFO] LLM总参数量：26.878 百万
2025-01-18 16:49:07,244 [INFO] 处理完成代码文件数量: 5655
2025-01-18 16:49:21,171 [INFO] 数据集长度: 35162
2025-01-18 16:49:22,872 [INFO] Epoch 0 首批次参数变化量: 0.00000875
2025-01-18 16:49:22,873 [INFO] Epoch 0, Batch 0, Loss: 5.7060
2025-01-18 16:49:26,483 [INFO] Epoch 0, Batch 10, Loss: 4.2867
2025-01-18 16:49:30,096 [INFO] Epoch 0, Batch 20, Loss: 3.8701
2025-01-18 16:49:33,703 [INFO] Epoch 0, Batch 30, Loss: 3.4533
2025-01-18 16:49:37,313 [INFO] Epoch 0, Batch 40, Loss: 3.2730
2025-01-18 16:49:40,935 [INFO] Epoch 0, Batch 50, Loss: 2.9555
2025-01-18 16:49:44,562 [INFO] Epoch 0, Batch 60, Loss: 2.9344
2025-01-18 16:49:48,192 [INFO] Epoch 0, Batch 70, Loss: 2.8180
2025-01-18 16:49:51,827 [INFO] Epoch 0, Batch 80, Loss: 2.6265
2025-01-18 16:49:55,463 [INFO] Epoch 0, Batch 90, Loss: 2.6459
2025-01-18 16:49:59,103 [INFO] Epoch 0, Batch 100, Loss: 2.5754
2025-01-18 16:50:02,745 [INFO] Epoch 0, Batch 110, Loss: 2.3087
2025-01-18 16:50:06,390 [INFO] Epoch 0, Batch 120, Loss: 2.2804
2025-01-18 16:50:10,031 [INFO] Epoch 0, Batch 130, Loss: 2.1712
2025-01-18 16:50:13,674 [INFO] Epoch 0, Batch 140, Loss: 2.1423
2025-01-18 16:50:17,319 [INFO] Epoch 0, Batch 150, Loss: 2.1638
2025-01-18 16:50:20,964 [INFO] Epoch 0, Batch 160, Loss: 1.9969
2025-01-18 16:50:24,609 [INFO] Epoch 0, Batch 170, Loss: 2.1130
2025-01-18 16:50:28,253 [INFO] Epoch 0, Batch 180, Loss: 1.8903
2025-01-18 16:50:31,900 [INFO] Epoch 0, Batch 190, Loss: 2.0326
2025-01-18 16:50:35,543 [INFO] Epoch 0, Batch 200, Loss: 1.8933
2025-01-18 16:50:39,189 [INFO] Epoch 0, Batch 210, Loss: 1.8649
2025-01-18 16:50:42,838 [INFO] Epoch 0, Batch 220, Loss: 1.7703
2025-01-18 16:50:46,482 [INFO] Epoch 0, Batch 230, Loss: 1.8448
2025-01-18 16:50:50,126 [INFO] Epoch 0, Batch 240, Loss: 1.8654
2025-01-18 16:50:53,773 [INFO] Epoch 0, Batch 250, Loss: 1.6121
2025-01-18 16:50:57,419 [INFO] Epoch 0, Batch 260, Loss: 1.7077
2025-01-18 16:51:01,066 [INFO] Epoch 0, Batch 270, Loss: 1.5634
2025-01-18 16:51:04,712 [INFO] Epoch 0, Batch 280, Loss: 1.6975
2025-01-18 16:51:08,361 [INFO] Epoch 0, Batch 290, Loss: 1.6638
2025-01-18 16:51:12,009 [INFO] Epoch 0, Batch 300, Loss: 1.7139
2025-01-18 16:51:15,655 [INFO] Epoch 0, Batch 310, Loss: 1.6763
2025-01-18 16:51:19,301 [INFO] Epoch 0, Batch 320, Loss: 1.5224
2025-01-18 16:51:22,950 [INFO] Epoch 0, Batch 330, Loss: 1.5901
2025-01-18 16:51:26,599 [INFO] Epoch 0, Batch 340, Loss: 1.5182
2025-01-18 16:51:30,244 [INFO] Epoch 0, Batch 350, Loss: 1.6822
2025-01-18 16:51:33,893 [INFO] Epoch 0, Batch 360, Loss: 1.4748
2025-01-18 16:51:37,541 [INFO] Epoch 0, Batch 370, Loss: 1.5621
2025-01-18 16:51:41,190 [INFO] Epoch 0, Batch 380, Loss: 1.5058
2025-01-18 16:51:44,837 [INFO] Epoch 0, Batch 390, Loss: 1.4316
2025-01-18 16:51:48,486 [INFO] Epoch 0, Batch 400, Loss: 1.4722
2025-01-18 16:51:52,136 [INFO] Epoch 0, Batch 410, Loss: 1.4319
2025-01-18 16:51:55,786 [INFO] Epoch 0, Batch 420, Loss: 1.5101
2025-01-18 16:51:59,433 [INFO] Epoch 0, Batch 430, Loss: 1.5487
2025-01-18 16:52:02,611 [INFO] Epoch 0 优化器学习率: 0.00000750
2025-01-18 16:52:02,612 [INFO] Epoch 0 优化器状态大小: 232
2025-01-18 16:52:02,648 [INFO] Epoch 0 Average Loss: 2.1219
2025-01-18 16:52:04,000 [INFO] Epoch 1 首批次参数变化量: 0.00000261
2025-01-18 16:52:04,000 [INFO] Epoch 1, Batch 0, Loss: 1.4385
2025-01-18 16:52:07,648 [INFO] Epoch 1, Batch 10, Loss: 1.5577
2025-01-18 16:52:11,295 [INFO] Epoch 1, Batch 20, Loss: 1.4591
2025-01-18 16:52:14,942 [INFO] Epoch 1, Batch 30, Loss: 1.5419
2025-01-18 16:52:18,590 [INFO] Epoch 1, Batch 40, Loss: 1.3589
2025-01-18 16:52:22,238 [INFO] Epoch 1, Batch 50, Loss: 1.4698
2025-01-18 16:52:25,886 [INFO] Epoch 1, Batch 60, Loss: 1.3816
2025-01-18 16:52:29,534 [INFO] Epoch 1, Batch 70, Loss: 1.4525
2025-01-18 16:52:33,184 [INFO] Epoch 1, Batch 80, Loss: 1.2664
2025-01-18 16:52:36,831 [INFO] Epoch 1, Batch 90, Loss: 1.3822
2025-01-18 16:52:40,481 [INFO] Epoch 1, Batch 100, Loss: 1.2754
2025-01-18 16:52:44,129 [INFO] Epoch 1, Batch 110, Loss: 1.3811
2025-01-18 16:52:47,779 [INFO] Epoch 1, Batch 120, Loss: 1.2462
2025-01-18 16:52:51,430 [INFO] Epoch 1, Batch 130, Loss: 1.4076
2025-01-18 16:52:55,079 [INFO] Epoch 1, Batch 140, Loss: 1.4074
2025-01-18 16:52:58,729 [INFO] Epoch 1, Batch 150, Loss: 1.4229
2025-01-18 16:53:02,381 [INFO] Epoch 1, Batch 160, Loss: 1.3151
2025-01-18 16:53:06,033 [INFO] Epoch 1, Batch 170, Loss: 1.3638
2025-01-18 16:53:09,685 [INFO] Epoch 1, Batch 180, Loss: 1.2144
2025-01-18 16:53:13,336 [INFO] Epoch 1, Batch 190, Loss: 1.3478
2025-01-18 16:53:16,983 [INFO] Epoch 1, Batch 200, Loss: 1.3318
2025-01-18 16:53:20,633 [INFO] Epoch 1, Batch 210, Loss: 1.3616
2025-01-18 16:53:24,281 [INFO] Epoch 1, Batch 220, Loss: 1.3464
2025-01-18 16:53:27,932 [INFO] Epoch 1, Batch 230, Loss: 1.3473
2025-01-18 16:53:31,580 [INFO] Epoch 1, Batch 240, Loss: 1.3020
2025-01-18 16:53:35,229 [INFO] Epoch 1, Batch 250, Loss: 1.3704
2025-01-18 16:53:38,878 [INFO] Epoch 1, Batch 260, Loss: 1.3466
2025-01-18 16:53:42,526 [INFO] Epoch 1, Batch 270, Loss: 1.2805
2025-01-18 16:53:46,175 [INFO] Epoch 1, Batch 280, Loss: 1.3001
2025-01-18 16:53:49,825 [INFO] Epoch 1, Batch 290, Loss: 1.2503
2025-01-18 16:53:53,473 [INFO] Epoch 1, Batch 300, Loss: 1.3108
2025-01-18 16:53:57,123 [INFO] Epoch 1, Batch 310, Loss: 1.3241
2025-01-18 16:54:00,770 [INFO] Epoch 1, Batch 320, Loss: 1.3008
2025-01-18 16:54:04,420 [INFO] Epoch 1, Batch 330, Loss: 1.2374
2025-01-18 16:54:08,067 [INFO] Epoch 1, Batch 340, Loss: 1.1430
2025-01-18 16:54:11,720 [INFO] Epoch 1, Batch 350, Loss: 1.1709
2025-01-18 16:54:15,370 [INFO] Epoch 1, Batch 360, Loss: 1.2928
2025-01-18 16:54:19,021 [INFO] Epoch 1, Batch 370, Loss: 1.2644
2025-01-18 16:54:22,671 [INFO] Epoch 1, Batch 380, Loss: 1.2669
2025-01-18 16:54:26,322 [INFO] Epoch 1, Batch 390, Loss: 1.3484
2025-01-18 16:54:29,972 [INFO] Epoch 1, Batch 400, Loss: 1.2641
2025-01-18 16:54:33,621 [INFO] Epoch 1, Batch 410, Loss: 1.3235
2025-01-18 16:54:37,270 [INFO] Epoch 1, Batch 420, Loss: 1.1712
2025-01-18 16:54:40,917 [INFO] Epoch 1, Batch 430, Loss: 1.2175
2025-01-18 16:54:44,109 [INFO] Epoch 1 优化器学习率: 0.00000250
2025-01-18 16:54:44,109 [INFO] Epoch 1 优化器状态大小: 232
2025-01-18 16:54:44,113 [INFO] Epoch 1 Average Loss: 1.3449
2025-01-18 16:54:45,493 [INFO] Epoch 2 首批次参数变化量: 0.00000081
2025-01-18 16:54:45,493 [INFO] Epoch 2, Batch 0, Loss: 1.2650
2025-01-18 16:54:49,152 [INFO] Epoch 2, Batch 10, Loss: 1.1585
2025-01-18 16:54:52,799 [INFO] Epoch 2, Batch 20, Loss: 1.3125
2025-01-18 16:54:56,448 [INFO] Epoch 2, Batch 30, Loss: 1.1427
2025-01-18 16:55:00,097 [INFO] Epoch 2, Batch 40, Loss: 1.2508
2025-01-18 16:55:03,746 [INFO] Epoch 2, Batch 50, Loss: 1.2695
2025-01-18 16:55:07,394 [INFO] Epoch 2, Batch 60, Loss: 1.2327
2025-01-18 16:55:11,042 [INFO] Epoch 2, Batch 70, Loss: 1.2375
2025-01-18 16:55:14,689 [INFO] Epoch 2, Batch 80, Loss: 1.2999
2025-01-18 16:55:18,336 [INFO] Epoch 2, Batch 90, Loss: 1.1410
2025-01-18 16:55:21,984 [INFO] Epoch 2, Batch 100, Loss: 1.3585
2025-01-18 16:55:25,633 [INFO] Epoch 2, Batch 110, Loss: 1.2874
2025-01-18 16:55:29,282 [INFO] Epoch 2, Batch 120, Loss: 1.1709
2025-01-18 16:55:32,932 [INFO] Epoch 2, Batch 130, Loss: 1.1839
2025-01-18 16:55:36,579 [INFO] Epoch 2, Batch 140, Loss: 1.3253
2025-01-18 16:55:40,229 [INFO] Epoch 2, Batch 150, Loss: 1.0656
2025-01-18 16:55:43,877 [INFO] Epoch 2, Batch 160, Loss: 1.1698
2025-01-18 16:55:47,527 [INFO] Epoch 2, Batch 170, Loss: 1.3270
2025-01-18 16:55:51,175 [INFO] Epoch 2, Batch 180, Loss: 1.3818
2025-01-18 16:55:54,825 [INFO] Epoch 2, Batch 190, Loss: 1.2581
2025-01-18 16:55:58,473 [INFO] Epoch 2, Batch 200, Loss: 1.2989
2025-01-18 16:56:02,122 [INFO] Epoch 2, Batch 210, Loss: 1.2045
2025-01-18 16:56:05,769 [INFO] Epoch 2, Batch 220, Loss: 1.1491
2025-01-18 16:56:09,419 [INFO] Epoch 2, Batch 230, Loss: 1.2963
2025-01-18 16:56:13,069 [INFO] Epoch 2, Batch 240, Loss: 1.2063
2025-01-18 16:56:16,718 [INFO] Epoch 2, Batch 250, Loss: 1.2239
2025-01-18 16:56:20,365 [INFO] Epoch 2, Batch 260, Loss: 1.1904
2025-01-18 16:56:24,016 [INFO] Epoch 2, Batch 270, Loss: 1.2332
2025-01-18 16:56:27,665 [INFO] Epoch 2, Batch 280, Loss: 1.2261
2025-01-18 16:56:31,314 [INFO] Epoch 2, Batch 290, Loss: 1.2125
2025-01-18 16:56:34,964 [INFO] Epoch 2, Batch 300, Loss: 1.1207
2025-01-18 16:56:38,615 [INFO] Epoch 2, Batch 310, Loss: 1.3413
2025-01-18 16:56:42,265 [INFO] Epoch 2, Batch 320, Loss: 1.1936
2025-01-18 16:56:45,915 [INFO] Epoch 2, Batch 330, Loss: 1.3581
2025-01-18 16:56:49,564 [INFO] Epoch 2, Batch 340, Loss: 1.2277
2025-01-18 16:56:53,214 [INFO] Epoch 2, Batch 350, Loss: 1.3490
2025-01-18 16:56:56,865 [INFO] Epoch 2, Batch 360, Loss: 1.1733
2025-01-18 16:57:00,515 [INFO] Epoch 2, Batch 370, Loss: 1.1793
2025-01-18 16:57:04,163 [INFO] Epoch 2, Batch 380, Loss: 1.3362
2025-01-18 16:57:07,812 [INFO] Epoch 2, Batch 390, Loss: 1.1810
2025-01-18 16:57:11,461 [INFO] Epoch 2, Batch 400, Loss: 1.1768
2025-01-18 16:57:15,111 [INFO] Epoch 2, Batch 410, Loss: 1.3000
2025-01-18 16:57:18,763 [INFO] Epoch 2, Batch 420, Loss: 1.2275
2025-01-18 16:57:22,411 [INFO] Epoch 2, Batch 430, Loss: 1.2815
2025-01-18 16:57:25,616 [INFO] Epoch 2 优化器学习率: 0.00000000
2025-01-18 16:57:25,617 [INFO] Epoch 2 优化器状态大小: 232
2025-01-18 16:57:25,620 [INFO] Epoch 2 Average Loss: 1.2434
